{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization for medical image segmentation with 2D U-Net on Intel(R) Xeon CPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agenda\n",
    "\n",
    "1. Brain MRI scan\n",
    "2. U-Net for brain images segmentation\n",
    "3. Intel's optimizations\n",
    "5. Let's do coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Brain MRI scan\n",
    "Magnetic resonance imaging (MRI) of the brain is a safe and painless test that uses a magnetic field and radio waves to produce detailed images of the brain and the brain stem. An MRI differs from a CAT scan (also called a CT scan or a computed axial tomography scan) because it does not use radiation.\n",
    "\n",
    "An MRI scanner consists of a large doughnut-shaped magnet that often has a tunnel in the center. Patients are placed on a table that slides into the tunnel. Some centers have open MRI machines that have larger openings and are helpful for patients with claustrophobia. MRI machines are located in hospitals and radiology centers.\n",
    "\n",
    "During the exam, radio waves manipulate the magnetic position of the atoms of the body, which are picked up by a powerful antenna and sent to a computer. The computer performs millions of calculations, resulting in clear, cross-sectional black and white images of the body. These images can be converted into three-dimensional (3-D) pictures of the scanned area. This helps pinpoint problems in the brain and the brain stem when the scan focuses on those areas.\n",
    "\n",
    "**Reference:** https://kidshealth.org/en/parents/mri-brain.html\n",
    "\n",
    "<table><tr><td><img src='https://github.com/IntelAI/unet/raw/master/3D/images/BRATS_152_img3D.gif'></td><td><img src='https://github.com/IntelAI/unet/blob/master/3D/images/BRATS_195_img.gif?raw=true'></td></tr></table>\n",
    "\n",
    "**Reference:** https://github.com/IntelAI/unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. U-Net for brain images segmentation\n",
    "\n",
    "U-Net implementation in TensorFlow for FLAIR abnormality segmentation in brain MRI based on a deep learning segmentation algorithm used in [Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm](https://doi.org/10.1016/j.compbiomed.2019.05.002).\n",
    "\n",
    "```latex\n",
    "@article{buda2019association,\n",
    "  title={Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm},\n",
    "  author={Buda, Mateusz and Saha, Ashirbani and Mazurowski, Maciej A},\n",
    "  journal={Computers in Biology and Medicine},\n",
    "  volume={109},\n",
    "  year={2019},\n",
    "  publisher={Elsevier},\n",
    "  doi={10.1016/j.compbiomed.2019.05.002}\n",
    "}\n",
    "```\n",
    "\n",
    "Topology structured as the following:\n",
    "<img src='https://github.com/mateuszbuda/brain-segmentation-pytorch/raw/master/assets/unet.png'>\n",
    "\n",
    "**Reference:** https://github.com/mateuszbuda/brain-segmentation-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Intel's optimization\n",
    "\n",
    "#### Intel Optimization for Tensorflow\n",
    "\n",
    "In order to take full advantage of Intel® architecture and to extract maximum performance, the TensorFlow framework has been optimized with Intel® Math Kernel Library for Deep Neural Networks (Intel® oneDNN) primitives, a popular performance library for deep learning applications.\n",
    "\n",
    "For more information about the optimizations as well as performance data, see the blog post:[TensorFlow Optimizations on Modern Intel® Architecture](https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture).\n",
    "\n",
    "Installation guide of Intel Optimization for TensorFlow can be found at [Intel® Optimization for TensorFlow Installation Guide](https://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide).\n",
    "\n",
    "\n",
    "#### 3.1 Optimization with TensorFlow switches\n",
    "**intra_op_parallelism_threads**\n",
    "- Number of threads in each threadpool for an operation (like matrix multiplication or reduction). \n",
    "- Recommend: #physical cores, found in Linux with ‘lscpu’ command. \n",
    "\n",
    "**inter_op_parallelism_threads**\n",
    "- Number of thread pools for independent operations.\n",
    "- Recommend: #cpu sockets,  found in Linux with ‘lscpu’ command.\n",
    "\n",
    "Note, need to test with the model & platform to find the best parameters.\n",
    "\n",
    "#### 3.2 Optimization with Intel(R) oneDNN switches\n",
    "Intel oneDNN utilizes OpenMP to leverage Intel architecture.\n",
    "Following environment variables for vectorization and multi-threading.\n",
    "\n",
    "**KMP_AFFINITY**\n",
    "- Restricts execution of certain threads to a subset of the physical processing units in a multiprocessor computer.\n",
    "- Recommend: ```export KMP_AFFINITY=granularity=fine,compact,1,0```\n",
    "\n",
    "**KMP_BLOCKTIME**\n",
    "- Set the time (milliseconds), that a thread wait for, after completing the execution of a parallel region, before sleeping. \n",
    "- Recommend: ```export KMP_BLOCKTIME=0 (or 1)```\n",
    "\n",
    "**OMP_NUM_THREADS**\n",
    "- Set maximum number of threads to use for OpenMP parallel regions\n",
    "- Recommend: ```export OMP_NUM_THREADS=num physical cores```\n",
    "\n",
    "Note, recommend users tuning these values for their specific neural network model and platform.\n",
    "\n",
    "#### 3.3 Optimization with miscellaneous configurations/tools\n",
    "**Numactl**\n",
    "- Running on a NUMA-enabled machine brings with it special considerations. NUMA or non-uniform memory access is a memory layout design used in data center machines meant to take advantage of locality of memory in multi-socket machines with multiple memory controllers and blocks. In most cases, inference runs best when confining both the execution and memory usage to a single NUMA node.\n",
    "- Recommend: ```numactl --cpunodebind=N --membind=N python <pytorch_script>```\n",
    "\n",
    "**Batch size**\n",
    "- Can increase usage and efficiency of hardware resources.\n",
    "- Optional according to your requirements.\n",
    "- Recommend: $2^{n}, n \\in N_+$\n",
    "\n",
    "A more detailed introduction of maximizing performance with Intel Optimization for TensorFlow can be found [here](https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Let's do coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0 Dataset\n",
    "We use [brain tumor segmentation (BraTS) subset](https://drive.google.com/file/d/1A2IU8Sgea1h3fYLpYtFb2v7NYdMjvEhU/view?usp=sharing) of the [Medical Segmentation Decathlon](http://medicaldecathlon.com/) dataset. The dataset has the [Creative Commons Attribution-ShareAlike 4.0 International license](https://creativecommons.org/licenses/by-sa/4.0/).\n",
    "\n",
    "Please follow instructions [here](https://github.com/IntelAI/unet/blob/master/2D/00_Prepare-Data.ipynb) to prepare the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "import h5py\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import load_data\n",
    "from model import unet\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "from argparser import args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Check TensorFlow version, and do sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"We are using Tensorflow version\", tf.__version__,\\\n",
    "       \"with Intel(R) oneDNN\", \"enabled\" if tf.pywrap_tensorflow.IsMklEnabled() else \"disabled\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Define the DICE coefficient and loss function\n",
    "The Sørensen–Dice coefficient is a statistic used for comparing the similarity of two samples. Given two sets, X and Y, it is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "Dice = \\frac{2|X\\cap Y|}{|X|+|Y|}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(target, prediction, smooth=0.01):\n",
    "    \"\"\"\n",
    "    Sorensen Dice coefficient\n",
    "    \"\"\"\n",
    "    prediction = np.round(prediction)\n",
    "\n",
    "    numerator = 2.0 * np.sum(target * prediction) + smooth\n",
    "    denominator = np.sum(target) + np.sum(prediction) + smooth\n",
    "    coef = numerator / denominator\n",
    "\n",
    "    return coef\n",
    "\n",
    "def calc_soft_dice(target, prediction, smooth=0.01):\n",
    "    \"\"\"\n",
    "    Sorensen (Soft) Dice coefficient - Don't round preictions\n",
    "    \"\"\"\n",
    "    numerator = 2.0 * np.sum(target * prediction) + smooth\n",
    "    denominator = np.sum(target) + np.sum(prediction) + smooth\n",
    "    coef = numerator / denominator\n",
    "\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"../../data/decathlon/144x144/\")\n",
    "data_filename = \"Task01_BrainTumour.h5\"\n",
    "hdf5_filename = os.path.join(data_path, data_filename)\n",
    "imgs_train, msks_train, imgs_validation, msks_validation, imgs_testing, msks_testing = load_data(hdf5_filename)\n",
    "imgs_warmup=imgs_testing[:500]\n",
    "imgs_infere=imgs_testing[500:2500]\n",
    "print(\"Number of imgs_warmup: {}\".format(imgs_warmup.shape[0]))\n",
    "print(\"Number of imgs_infere: {}\".format(imgs_infere.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = unet()\n",
    "model = unet_model.load_model(os.path.join(\"./output/unet_model_for_decathlon.hdf5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Define function to inference on input images and plot results out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, imgs_validation, msks_validation, img_no):\n",
    "    img = imgs_validation[idx:idx+1]\n",
    "    msk = msks_validation[idx:idx+1]\n",
    "    \n",
    "    pred_mask = model.predict(img, verbose=1, steps=None)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img[0, :, :, 0], cmap=\"bone\", origin=\"lower\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"MRI Input\", fontsize=20)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(msk[0, :, :, 0], origin=\"lower\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Ground truth\", fontsize=20)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred_mask[0, :, :, 0], origin=\"lower\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Prediction\\nDice = {:.4f}\".format(calc_dice(pred_mask, msk)), fontsize=20)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7 Run inference and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies_validation = [40, 63, 43, 55, 99]\n",
    "for idx in indicies_validation:\n",
    "    plot_results(model, imgs_validation, msks_validation, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.8 Benchmark\n",
    "\n",
    "See demo in console.\n",
    "\n",
    "- Single instance\n",
    "  - Batch size 1\n",
    "    - Without numactl\n",
    "      - Default configuration\n",
    "      - Configuration with optimization\n",
    "    - With numactl\n",
    "      - Default configuration\n",
    "      - Configuration with optimization\n",
    "  - Batch size 128\n",
    "    - With numactl\n",
    "      - Default configuration\n",
    "      - Configuration with optimization\n",
    "- Multiple instances\n",
    "  - Batch size 128\n",
    "    - Configuration with optimization\n",
    "      - 2 instances\n",
    "      - 4 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "SPDX-License-Identifier: EPL-2.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
